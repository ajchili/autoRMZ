{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoRMZ test/development notebook (v1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LICENSE    \u001b[34mdataset\u001b[m\u001b[m    \u001b[34mprocessor\u001b[m\u001b[m  test.png   v1.ipynb\nREADME.md  \u001b[34mpipeline\u001b[m\u001b[m   setup.py   testing.py\n"
    }
   ],
   "source": [
    "# List all files to ensure all dependencies exist.\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data paths\n",
    "preprocessed_path = Path('./dataset/preprocessed')\n",
    "processed_path = Path('./dataset/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files from data paths\n",
    "preprocessed_images = [e for e in preprocessed_path.iterdir() if e.is_file()]\n",
    "processed_json = [e for e in processed_path.iterdir() if e.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Crop preprocessed data with processed data to obtain dataset to be used for training.\n",
    "if not Path('./dataset/roi').is_dir():\n",
    "    Path('./dataset/roi').mkdir()\n",
    "\n",
    "for json_file in processed_json:\n",
    "    data_point_name = json_file.name[:-5]\n",
    "    image_file = Path('./dataset/preprocessed/{}.png'.format(data_point_name))\n",
    "    crop_areas = []\n",
    "    with json_file.open() as f:\n",
    "        crop_areas = json.load(f)['areas']\n",
    "    \n",
    "    image_path = str(image_file.absolute())\n",
    "    im = cv2.imread(image_path)\n",
    "\n",
    "    im_path = Path('./dataset/roi/{}'.format(data_point_name))\n",
    "\n",
    "    if not im_path.is_dir():\n",
    "        im_path.mkdir()\n",
    "    \n",
    "    for j in range(0, len(crop_areas)):\n",
    "        area = crop_areas[j]\n",
    "        x = min(area['p1'][0], area['p2'][0])\n",
    "        y = min(area['p1'][1], area['p2'][1])\n",
    "        width = abs(area['p1'][0] - area['p2'][0])\n",
    "        height = abs(area['p1'][1] - area['p2'][1])\n",
    "        # print(x, y, x+width, y+height)\n",
    "        roi = im[y:y+height, x:x+width]\n",
    "        roi_path = Path('./dataset/roi/{}/{}.png'.format(data_point_name, j)).absolute()\n",
    "        cv2.imwrite(str(roi_path), roi)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}